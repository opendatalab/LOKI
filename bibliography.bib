@misc{bennett2010openstreetmap,
  title={OpenStreetMap},
  publisher={Bennett, Jonathan},
  author={Bennett, Jonathan},
  year={2010},
}

@inproceedings{google_map_platform,
  title = {Google Map Platform},
  booktitle = {https://mapsplatform.google.com/},
  author={Google Map Team,}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{minderer2022simple,
  title={Simple Open-Vocabulary Object Detection with Vision Transformers},
  author={Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and others},
  booktitle={ECCV},
  year={2022},
}


@article{liu2023grounding,
  title={Grounding dino: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2303.05499},
  year={2023}
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{li2023blip,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
  author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
  year={2023},
  booktitle={ICML},
}

@inproceedings{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{dai2023instructblip,
    title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}, 
    author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
    year={2023},
    booktitle={NeurIPS}
}

@article{EVA-CLIP,
  title={EVA-CLIP: Improved Training Techniques for CLIP at Scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@inproceedings{openclip2023,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={CVPR},
  year={2023}
}

@article{zhai2023siglip,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  journal={arXiv preprint arXiv:2303.15343},
  year={2023}
}

@article{zhu2023minigpt,
  title={{MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models}},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{chen2023shikra,
  title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic},
  author={Chen, Keqin and Zhang, Zhao and Zeng, Weili and Zhang, Richong and Zhu, Feng and Zhao, Rui},
  journal={arXiv preprint arXiv:2306.15195},
  year={2023}
}


@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{liu2023improvedllava,
    title={Improved Baselines with Visual Instruction Tuning}, 
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
    journal={arXiv:2310.03744},
    year={2023},
}

@article{liu2023mmbench,
  title={MMBench: Is Your Multi-modal Model an All-around Player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{schulman2022chatgpt,
  title={ChatGPT: Optimizing language models for dialogue},
  author={Schulman, John and Zoph, Barret and Kim, Christina and Hilton, Jacob and Menick, Jacob and Weng, Jiayi and Uribe, Juan Felipe Ceron and Fedus, Liam and Metz, Luke and Pokorny, Michael and others},
  journal={OpenAI blog},
  year={2022}
}

@article{xi2023rise,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2023}
}

@article{wooldridge1995intelligent,
  title={Intelligent agents: Theory and practice},
  author={Wooldridge, Michael and Jennings, Nicholas R},
  journal={The knowledge engineering review},
  year={1995},
}

@inproceedings{chen2022visualgpt,
  title={Visualgpt: Data-efficient adaptation of pretrained language models for image captioning},
  author={Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
  booktitle={CVPR},
  year={2022}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={ICML},
  year={2022},
}

@inproceedings{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  booktitle={CoRL},
  year={2022}
}
@inproceedings{brohan2023can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Brohan, Anthony and Chebotar, Yevgen and Finn, Chelsea and Hausman, Karol and Herzog, Alexander and Ho, Daniel and Ibarz, Julian and Irpan, Alex and Jang, Eric and Julian, Ryan and others},
  booktitle={CoRL},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={UIST},
  year={2023}
}

@article{du2009pp,
  title={PP-OCR: A practical ultra lightweight OCR system. arXiv 2020},
  author={Du, Y and Li, C and Guo, R and Yin, X and Liu, W and Zhou, J and Bai, Y and Yu, Z and Yang, Y and Dang, Q and others},
  journal={arXiv preprint arXiv:2009.09941},
  year={2020}
}

@misc{Significant_Gravitas_AutoGPT,
    title = {{AutoGPT}},
    author = {{Significant Gravitas}},
    howpublished = {\url{https://github.com/Significant-Gravitas/AutoGPT}},
    year= {2023}
}

@article{nakano2021webgpt,
  title={{WebGPT: Browser-assisted question-answering with human feedback}},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@inproceedings{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  booktitle={NeurIPS},
  year={2023}
}

@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{li2022languagedriven,
    title={Language-driven Semantic Segmentation},
    author={Boyi Li and Kilian Q Weinberger and Serge Belongie and Vladlen Koltun and Rene Ranftl},
    booktitle={ICLR},
    year={2022},
}

@inproceedings{ramaswamy2023geode,
  title={Geode: a geographically diverse evaluation dataset for object recognition},
  author={Ramaswamy, Vikram V and Lin, Sing Yu and Zhao, Dora and Adcock, Aaron Bryan and van der Maaten, Laurens and Ghadiyaram, Deepti and Russakovsky, Olga},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{deng2009imagenet,
  title={Image{N}et: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@article{kuznetsova2020open,
  title={The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal={IJCV},
  year={2020}
}

@inproceedings{dubey2021adaptive,
  title={Adaptive methods for real-world domain generalization},
  author={Dubey, Abhimanyu and Ramanathan, Vignesh and Pentland, Alex and Mahajan, Dhruv},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{asano2021pass,
  title={Pass: An imagenet replacement for self-supervised pretraining without humans},
  author={Asano, Yuki M and Rupprecht, Christian and Zisserman, Andrew and Vedaldi, Andrea},
  booktitle={NeurIPS},
  year={2021}
}


@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{xia2018gibson,
  title={Gibson env: Real-world perception for embodied agents},
  author={Xia, Fei and Zamir, Amir R and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{makoviychuk2021isaac,
  title={Isaac gym: High performance gpu-based physics simulation for robot learning},
  author={Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and others},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{lindenberger2023lightglue,
  title={LightGlue: Local Feature Matching at Light Speed},
  author={Lindenberger, Philipp and Sarlin, Paul-Edouard and Pollefeys, Marc},
  booktitle={ICCV},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@inproceedings{kuttler2020nethack,
  title={The nethack learning environment},
  author={K{\"u}ttler, Heinrich and Nardelli, Nantas and Miller, Alexander and Raileanu, Roberta and Selvatici, Marco and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle={NeurIPS},
  year={2020}
}

@article{schumann2023velma,
  title={Velma: Verbalization embodiment of llm agents for vision and language navigation in street view},
  author={Schumann, Raphael and Zhu, Wanrong and Feng, Weixi and Fu, Tsu-Jui and Riezler, Stefan and Wang, William Yang},
  journal={arXiv preprint arXiv:2307.06082},
  year={2023}
}

@inproceedings{schumann2020generating,
  title={Generating landmark navigation instructions from maps as a graph-to-text problem},
  author={Schumann, Raphael and Riezler, Stefan},
  booktitle={ACL},
  year={2020}
}

@inproceedings{chen2019touchdown,
  title={Touchdown: Natural language navigation and spatial reasoning in visual street environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={CVPR},
  year={2019}
}

@article{zamir2014image,
  title={Image geo-localization based on multiplenearest neighbor feature matching usinggeneralized graphs},
  journal={TPAMI},
  year={2014},
}

@inproceedings{frome2009large,
  title={Large-scale privacy protection in google street view},
  author={Frome, Andrea and Cheung, German and Abdulkader, Ahmad and Zennaro, Marco and Wu, Bo and Bissacco, Alessandro and Adam, Hartwig and Neven, Hartmut and Vincent, Luc},
  booktitle={ICCV},
  year={2009}
}

@inproceedings{li2023internet,
    title={Internet Explorer: Targeted Representation Learning on the Open Web}, 
    author={Li, Alexander C and Brown, Ellis and Efros, Alexei A and Pathak, Deepak},
    booktitle={ICML},
    year={2023}
}

@article{wu2023vstar,
    title={{V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs}},
    author={Wu, Penghao and Xie, Saining},
    journal={arXiv preprint arXiv:2312.14135},
    year={2023}
}

@article{xu2023demystifying,
  title={Demystifying clip data},
  author={Xu, Hu and Xie, Saining and Tan, Xiaoqing Ellen and Huang, Po-Yao and Howes, Russell and Sharma, Vasu and Li, Shang-Wen and Ghosh, Gargi and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2309.16671},
  year={2023}
}

@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  year={2016},
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@inproceedings{schuhmann2022laionb,
  title={LAION-5B: An open large-scale dataset for training next generation image-text models},
  author={Christoph Schuhmann and
          Romain Beaumont and
          Richard Vencu and
          Cade W Gordon and
          Ross Wightman and
          Mehdi Cherti and
          Theo Coombes and
          Aarush Katta and
          Clayton Mullis and
          Mitchell Wortsman and
          Patrick Schramowski and
          Srivatsa R Kundurthy and
          Katherine Crowson and
          Ludwig Schmidt and
          Robert Kaczmarczyk and
          Jenia Jitsev},
  booktitle={NeurIPS},
  year={2022},
}

@inproceedings{laurenccon2023obelisc,
  title={Obelisc: An open web-scale filtered dataset of interleaved image-text documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, L{\'e}o and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M and Kiela, Douwe and others},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{zhou2022detecting,
  title={Detecting Twenty-thousand Classes using Image-level Supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Philipp and Misra, Ishan},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{ghiasi2022scaling,
  title={Scaling open-vocabulary image segmentation with image-level labels},
  author={Ghiasi, Golnaz and Gu, Xiuye and Cui, Yin and Lin, Tsung-Yi},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{xu2022groupvit,
  title={Groupvit: Semantic segmentation emerges from text supervision},
  author={Xu, Jiarui and De Mello, Shalini and Liu, Sifei and Byeon, Wonmin and Breuel, Thomas and Kautz, Jan and Wang, Xiaolong},
  booktitle={CVPR},
  year={2022}
}

@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@inproceedings{rojas2022dollar,
  title={The dollar street dataset: Images representing the geographic and socioeconomic diversity of the world},
  author={Rojas, William A Gaviria and Diamos, Sudnya and Kini, Keertan Ranjan and Kanter, David and Reddi, Vijay Janapa and Coleman, Cody},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{zhang2023openseed,
  title={A simple framework for open-vocabulary segmentation and detection},
  author={Zhang, Hao and Li, Feng and Zou, Xueyan and Liu, Shilong and Li, Chunyuan and Yang, Jianwei and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1020--1031},
  year={2023}
}

@article{minderer2024owlvitv2,
  title={Scaling open-vocabulary object detection},
  author={Minderer, Matthias and Gritsenko, Alexey and Houlsby, Neil},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
