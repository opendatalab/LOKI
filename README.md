<h2 align="center"><img style="height: 35px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/loki.png">$\LARGE\textbf{\textsf{{\color[rgb]{1.0, 0.7, 0.0}L}{\color[rgb]{1.0, 0.6, 0.0}O}{\color[rgb]{1.0, 0.5, 0.0}K}{\color[rgb]{1.0, 0.4, 0.0}I}}}{\color[rgb]{0,0,0}:}$ 
 A Comprehensive Synthetic Data Detection Benchmark using Large Mnultimodal Models<h5 align="center">



## &#x1F389; News



## &#x1F525; Takeaways
<p class="text">
            â€¢ <strong>Diverse modalities:</strong> Our dataset includes high-quality multimodal data generated by recent
            popular synthetic models, covering 
            $\color{#ffb60dde}{\textbf{video}}$,
            $\color{rgba(83, 164, 251, 1)}{\textbf{image}}$,
            $\color{rgba(41, 208, 108, 1)}{\textbf{3D}}$,
            $\color{rgb(166, 72, 255)}{\textbf{text}}$,
            $\color{rgb(255, 58, 58)}{\textbf{audio}}$, while ensuring
            paired real samples from the same domain. <br>
            â€¢ <strong>Heterogeneous category:</strong> Our collected dataset includes <strong>26</strong> detailed categories across different modalities, such as professional <img style="height: 30px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/satellite.png">statellite images, 
            <img style="height: 30px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/medical.png">medical images, <img style="height: 35px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/philosophy.png">philosophical and
            <img style="height: 30px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/ancient-literature.png">ancient chinese text, as well as $\color{rgb(255, 58, 58)}{\textbf{audio}}$ data like 
            <img style="height: 30px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/singing.png">singing voice and <img style="height: 30px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/music.png">music. <br>
            â€¢ <strong>Multi-level tasks:</strong> Our benchmark includes basic true/false labels for tasks such as <img style="height: 25px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/judgement.png"> judgment
            and <img style="height: 25px;" src="https://github.com/opendatalab/LOKI/blob/27f9fa838ee344798e210ee00fa70ab1b32ef6ae/static/img/icons/selection.png"> multiple-choice questions. Additionally, it features fine-grained abnormality annotations for explanation-based questions, aimed at exploring the capabilities of large multimodal models (LMMs) in Transparent Defake detection. <br>
            â€¢ <strong>Multimodal synthetic data evaluation framework:</strong> We propose a comprehensive multimodal
            evaluation framework that supports the input of various data formats, including $\color{#ffb60dde}{\textbf{video}}$, 
            $\color{rgba(83, 164, 251, 1)}{\textbf{image}}$, 
            $\color{rgb(166, 72, 255)}{\textbf{text}}$, 
            $\color{rgb(255, 58, 58)}{\textbf{audio}}$, and 
            $\color{rgba(116, 116, 116, 0.765)}{\textbf{point cloud}}$, into mainstream multimodal models.
</p>

## ðŸ“š Contents

- [ðŸŽ‰ News](#-news)
- [ðŸ”¥ Takeaways](#-takeaways)
- [ðŸ“š Contents](#-contents)
